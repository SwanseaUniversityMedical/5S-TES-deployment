services:

  # ------ Camunda Orchestration ------
  # -----------------------------------------

  orchestration: # Consolidated Zeebe + Operate + Tasklist - https://docs.camunda.io/docs/self-managed/setup/deploy/other/docker/#zeebe
    image: camunda/camunda:${CAMUNDA_VERSION}
    container_name: orchestration
    ports:
      - "26500:26500"
      - "9600:9600"
      - "8088:8080"
    environment:
      - JAVA_TOOL_OPTIONS="-XX:+PrintFlagsFinal"
    mem_limit: 1g
    restart: always
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "bash -c 'exec 3<>/dev/tcp/127.0.0.1/9600 && echo -e \"GET /actuator/health/status HTTP/1.1\r\nHost: localhost\r\n\r\n\" >&3 && head -n 1 <&3'",
        ]
      interval: 1s
      retries: 30
      start_period: 30s
    volumes:
      - zeebe:/usr/local/zeebe/data
    configs:
      - source: orchestration-config
        target: /usr/local/camunda/config/application.yaml
    networks:
      - sub-net
    depends_on:
      elasticsearch:
        condition: service_healthy

  # ------ Camunda Connectors ------
  # -----------------------------------------

  connectors:
    image: camunda/connectors-bundle:${CAMUNDA_BUNDLE_VERSION}
    container_name: connectors
    ports:
      - "8086:8080"
    environment:
      - management.endpoints.web.exposure.include=health,configprops
      - management.endpoint.health.probes.enabled=true

    # ------ env_file: connector-secrets.txt ------
    mem_limit: 512m
    restart: unless-stopped
    healthcheck:
      test:
        ["CMD-SHELL", "curl -f http://localhost:8080/actuator/health/readiness"]
      interval: 30s
      timeout: 1s
      retries: 5
      start_period: 30s
    configs:
      - source: connectors-config
        target: application.yaml
    networks:
      - sub-net
    depends_on:
      orchestration:
        # Wait for orchestration service to be healthy, otherwise we get a lot of noisy logs from connection errors
        condition: service_healthy

  # ------ OpenLDAP Identity Provider ------
  # ---------------------------------------------

  openldap:
    image: osixia/openldap:1.5.0
    container_name: openldap
    environment:
      LDAP_LOG_LEVEL: "256"
      LDAP_ORGANISATION: "TRE Ephemeral Credentials"
      LDAP_DOMAIN: "camundaephemeral.local"
      LDAP_ADMIN_PASSWORD: "admin"
      LDAP_CONFIG_PASSWORD: "config"
      LDAP_TLS: "false"
      LDAP_ADD_LDIF_URL: "file:///container/service/slapd/assets/init.ldif"
    volumes:
      - openldap_data:/var/lib/ldap
      - openldap_config:/etc/ldap/slapd.d
      - ${CONFIG_PATH}/ldap-init/init.ldif:/container/service/slapd/assets/init.ldif
    ports:
      - "1389:389"
      - "1636:636"
    networks:
      - sub-net
    domainname: "camundaephemeral.local"
    hostname: "ldap.camundaephemeral.local"
    tty: true
    stdin_open: true
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "ldapsearch -x -H ldap://localhost -b dc=camundaephemeral,dc=local -D 'cn=admin,dc=camundaephemeral,dc=local' -w admin",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # ------ LDAP Initialization Service ------
  # ---------------------------------------------

  ldap-init:
    image: osixia/openldap:1.5.0
    networks:
      - sub-net
    depends_on:
      openldap:
        condition: service_healthy
    entrypoint: >
      sh -c "
        for i in $(seq 1 30); do
          ldapsearch -x -H ldap://openldap -D 'cn=admin,dc=camundaephemeral,dc=local' -w admin -b 'dc=camundaephemeral,dc=local' && break
          sleep 2
        done
        ldapadd -x -H ldap://openldap -D 'cn=admin,dc=camundaephemeral,dc=local' -w admin -f /container/service/slapd/assets/init.ldif || true
      "
    volumes:
      - ${CONFIG_PATH}/ldap-init/init.ldif:/container/service/slapd/assets/init.ldif

  # ------ phpLDAPadmin Web Interface ------
  # ---------------------------------------------

  phpldapadmin:
    image: osixia/phpldapadmin:latest
    container_name: phpldapadmin
    networks:
      - sub-net
    environment:
      PHPLDAPADMIN_LDAP_HOSTS: "openldap"
      PHPLDAPADMIN_HTTPS: "false"
    ports:
      - "8080:80"
    depends_on:
      - openldap

 # ----- Vault Secret Management ------
 # ---------------------------------------------
  vault:
    image: hashicorp/vault:latest
    container_name: vault
    mem_limit: 512M
    mem_reservation: 256M
    cpus: 0.2
    restart: always
    ports:
      - "8200:8200"
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=dev-only-token
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_ADDR=http://127.0.0.1:8200
    volumes:
      - vault_data:/vault/data
      - vault_logs:/vault/logs
      - ${CONFIG_PATH}/vault-config:/vault/config:ro
    cap_add:
      - IPC_LOCK
    networks:
      - sub-net
    healthcheck:
      test: ["CMD-SHELL", "vault status || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    command: ["vault", "server", "-dev", "-dev-root-token-id=dev-only-token"]

  # ------ Elasticsearch ------
  # -----------------------------------

  elasticsearch: # https://hub.docker.com/_/elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      # allow running with low disk space
      - cluster.routing.allocation.disk.threshold_enabled=false
      # Disable noisy deprecation logs, see https://github.com/camunda/camunda/issues/26285
      - logger.org.elasticsearch.deprecation="OFF"
    mem_limit: 4g
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:9200/_cat/health | grep -q green",
        ]
      interval: 1s
      retries: 30
      start_period: 30s
      timeout: 1s
    volumes:
      - elastic:/usr/share/elasticsearch/data
    networks:
      - sub-net